{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the CSV file containing file names and labels\n",
    "csv_file_path = '/Users/dheemankumar/github/audio-ai/hindi_broken_3s_audio_data.csv'\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = []\n",
    "labels = []\n",
    "\n",
    "# Step 2 and 3: Load audio files and process the data with a sample rate of 22050\n",
    "for index, row in df.iterrows():\n",
    "    audio_file_path = '/Users/dheemankumar/github/audio-ai/3sec_audio/' + row['name']  # Adjust the path as needed\n",
    "    audio, sample_rate = librosa.load(audio_file_path, sr=22050)  # Load audio with a sample rate of 22050\n",
    "\n",
    "    # Perform additional processing if needed, e.g., creating spectrograms\\\n",
    "\n",
    "    d=librosa.stft(audio)\n",
    "    s_db=librosa.amplitude_to_db(np.abs(d),ref=np.max)\n",
    "\n",
    "    s_db_with_channel = np.expand_dims(s_db, axis=-1)\n",
    "\n",
    "    #print(s_db.shape)\n",
    "\n",
    "\n",
    "    # Append the processed audio data and label to the lists\n",
    "    audio_data.append(s_db_with_channel)\n",
    "    labels.append(row[['male','female']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create NumPy arrays\n",
    "audio_data = np.array(audio_data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779, 1025, 130, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 133250)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8528064   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8530309 (32.54 MB)\n",
      "Trainable params: 8530309 (32.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add a Flatten layer to convert the input shape to a 1D tensor\n",
    "model.add(layers.Flatten(input_shape=(1025,130,1)))\n",
    "\n",
    "# Add one or more hidden layers with desired units and activation functions\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer with 7 units (since you want 7 outputs) and a suitable activation function (e.g., softmax for classification)\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model with an appropriate loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(audio_data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(623, 1025, 130, 1), dtype=float32, numpy=\n",
       "array([[[[-65.06258 ],\n",
       "         [-68.19394 ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-69.91271 ],\n",
       "         [-80.      ],\n",
       "         [-70.99723 ]],\n",
       "\n",
       "        [[-64.97798 ],\n",
       "         [-68.402695],\n",
       "         [-78.414604],\n",
       "         ...,\n",
       "         [-67.16352 ],\n",
       "         [-69.45882 ],\n",
       "         [-66.37231 ]],\n",
       "\n",
       "        [[-65.77309 ],\n",
       "         [-66.4268  ],\n",
       "         [-72.61808 ],\n",
       "         ...,\n",
       "         [-64.82132 ],\n",
       "         [-64.48978 ],\n",
       "         [-68.21896 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]]],\n",
       "\n",
       "\n",
       "       [[[-56.909733],\n",
       "         [-66.480354],\n",
       "         [-64.0112  ],\n",
       "         ...,\n",
       "         [-71.59077 ],\n",
       "         [-55.708843],\n",
       "         [-50.209175]],\n",
       "\n",
       "        [[-51.897697],\n",
       "         [-55.512146],\n",
       "         [-55.455276],\n",
       "         ...,\n",
       "         [-61.64617 ],\n",
       "         [-63.891106],\n",
       "         [-50.465923]],\n",
       "\n",
       "        [[-44.33386 ],\n",
       "         [-43.754925],\n",
       "         [-49.619755],\n",
       "         ...,\n",
       "         [-65.04216 ],\n",
       "         [-57.46897 ],\n",
       "         [-48.473335]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]]],\n",
       "\n",
       "\n",
       "       [[[-52.21719 ],\n",
       "         [-58.618427],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-60.470173],\n",
       "         [-49.590286],\n",
       "         [-42.92228 ]],\n",
       "\n",
       "        [[-52.11971 ],\n",
       "         [-58.54729 ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-58.551258],\n",
       "         [-53.901115],\n",
       "         [-42.28446 ]],\n",
       "\n",
       "        [[-51.72184 ],\n",
       "         [-58.154808],\n",
       "         [-71.62053 ],\n",
       "         ...,\n",
       "         [-48.223427],\n",
       "         [-43.596825],\n",
       "         [-42.288376]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-73.06733 ],\n",
       "         [-64.03761 ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-73.069046],\n",
       "         [-64.039276]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-73.069405],\n",
       "         [-64.03982 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-57.315712],\n",
       "         [-57.994778],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-67.368454],\n",
       "         [-51.81083 ],\n",
       "         [-41.14849 ]],\n",
       "\n",
       "        [[-57.018673],\n",
       "         [-61.27366 ],\n",
       "         [-63.140118],\n",
       "         ...,\n",
       "         [-79.88431 ],\n",
       "         [-50.525597],\n",
       "         [-41.603172]],\n",
       "\n",
       "        [[-59.94645 ],\n",
       "         [-50.257053],\n",
       "         [-47.565468],\n",
       "         ...,\n",
       "         [-43.48696 ],\n",
       "         [-46.199055],\n",
       "         [-38.894356]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]]],\n",
       "\n",
       "\n",
       "       [[[-47.830357],\n",
       "         [-44.86568 ],\n",
       "         [-52.59801 ],\n",
       "         ...,\n",
       "         [-62.653046],\n",
       "         [-55.31341 ],\n",
       "         [-48.031754]],\n",
       "\n",
       "        [[-50.932934],\n",
       "         [-48.045452],\n",
       "         [-48.29994 ],\n",
       "         ...,\n",
       "         [-58.722992],\n",
       "         [-51.520298],\n",
       "         [-49.70706 ]],\n",
       "\n",
       "        [[-56.74975 ],\n",
       "         [-52.042194],\n",
       "         [-48.101475],\n",
       "         ...,\n",
       "         [-52.88444 ],\n",
       "         [-55.219284],\n",
       "         [-54.6707  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-73.930595]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-73.93199 ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-73.93253 ]]],\n",
       "\n",
       "\n",
       "       [[[-53.944942],\n",
       "         [-78.194855],\n",
       "         [-45.441715],\n",
       "         ...,\n",
       "         [-68.99867 ],\n",
       "         [-50.87626 ],\n",
       "         [-42.09644 ]],\n",
       "\n",
       "        [[-54.90638 ],\n",
       "         [-49.949432],\n",
       "         [-45.50233 ],\n",
       "         ...,\n",
       "         [-60.857727],\n",
       "         [-52.40935 ],\n",
       "         [-41.53606 ]],\n",
       "\n",
       "        [[-58.323547],\n",
       "         [-54.52971 ],\n",
       "         [-49.9791  ],\n",
       "         ...,\n",
       "         [-42.005672],\n",
       "         [-41.87684 ],\n",
       "         [-39.250572]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]],\n",
       "\n",
       "        [[-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         ...,\n",
       "         [-80.      ],\n",
       "         [-80.      ],\n",
       "         [-80.      ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 735.5680 - accuracy: 0.6822\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 169.8907 - accuracy: 0.7705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28ad36190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 1023, 128, 32)     320       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 511, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 509, 62, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 254, 31, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 503936)            0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                32251968  \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32270914 (123.10 MB)\n",
      "Trainable params: 32270914 (123.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model2 = models.Sequential()\n",
    "\n",
    "# Add a 2D convolutional layer with 32 filters, a 3x3 kernel, and 'relu' activation\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(1025, 130, 1)))\n",
    "\n",
    "# Add a max-pooling layer\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another 2D convolutional layer with 64 filters and 'relu' activation\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another max-pooling layer\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add a flattening layer to convert to 1D tensor\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "# Add a fully connected (dense) layer with 64 units and 'relu' activation\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Add the output layer with 7 units (since you want 7 outputs) and 'softmax' activation\n",
    "model2.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 5) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have already created the model and loaded your data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/yl/7n0txm9d01z7lfjlzgw92fb00000gn/T/__autograph_generated_fileq5jlfl64.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 5) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created the model and loaded your data\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.9872\n",
      "Test loss: 0.42092469334602356, Test accuracy: 0.9871794581413269\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_file_path = '/Users/dheemankumar/github/audio-ai/ab.wav'\n",
    "\n",
    "audio_file_path = '/Users/dheemankumar/github/audio-ai/female_eng.wav'  # Adjust the path as needed\n",
    "audio, sample_rate = librosa.load(audio_file_path, sr=22050)  # Load audio with a sample rate of 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=librosa.stft(audio)\n",
    "s_db=librosa.amplitude_to_db(np.abs(d),ref=np.max)\n",
    "\n",
    "s_db_with_channel = np.expand_dims(s_db, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = tf.convert_to_tensor(audio, dtype=tf.float32)\n",
    "audio_= np.array(s_db_with_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = audio_.reshape(1, 1025, 130, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000000e+00, 2.627575e-36, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
