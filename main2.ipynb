{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the CSV file containing file names and labels\n",
    "csv_file_path = '/Users/dheemankumar/Desktop/FILE/audio-ai/hindi_broken_3s_audio_data.csv'\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 2 and 3: Load audio files and process the data with a sample rate of 22050\n",
    "for index, row in df.iterrows():\n",
    "    audio_file_path = '/Users/dheemankumar/Desktop/FILE/audio-ai/3sec_audio/' + row['name']  # Adjust the path as needed\n",
    "    audio, sample_rate = librosa.load(audio_file_path, sr=22050)  # Load audio with a sample rate of 22050\n",
    "\n",
    "    # Perform additional processing if needed, e.g., creating spectrograms\\\n",
    "\n",
    "    d=librosa.stft(audio)\n",
    "    s_db=librosa.amplitude_to_db(np.abs(d),ref=np.max)\n",
    "\n",
    "    s_db_with_channel = np.expand_dims(s_db, axis=-1)\n",
    "\n",
    "    #print(s_db.shape)\n",
    "\n",
    "\n",
    "    # Append the processed audio data and label to the lists\n",
    "    audio_data.append(s_db_with_channel)\n",
    "    labels.append(row[['english','hindi','punjabi','bangoli','noise']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Create NumPy arrays\n",
    "audio_data = np.array(audio_data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(881, 5)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(881, 1025, 130, 1)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 133250)            0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8528064   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8530309 (32.54 MB)\n",
      "Trainable params: 8530309 (32.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add a Flatten layer to convert the input shape to a 1D tensor\n",
    "model.add(layers.Flatten(input_shape=(1025,130,1)))\n",
    "\n",
    "# Add one or more hidden layers with desired units and activation functions\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer with 7 units (since you want 7 outputs) and a suitable activation function (e.g., softmax for classification)\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model with an appropriate loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(audio_data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "22/22 [==============================] - 1s 18ms/step - loss: 574.0407 - accuracy: 0.7060\n",
      "Epoch 2/2\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 743.5485 - accuracy: 0.7798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x31b48afd0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 1023, 128, 32)     320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 511, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 509, 62, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 254, 31, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 503936)            0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                32251968  \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32271239 (123.11 MB)\n",
      "Trainable params: 32271239 (123.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model2 = models.Sequential()\n",
    "\n",
    "# Add a 2D convolutional layer with 32 filters, a 3x3 kernel, and 'relu' activation\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(1025, 130, 1)))\n",
    "\n",
    "# Add a max-pooling layer\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another 2D convolutional layer with 64 filters and 'relu' activation\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another max-pooling layer\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add a flattening layer to convert to 1D tensor\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "# Add a fully connected (dense) layer with 64 units and 'relu' activation\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Add the output layer with 7 units (since you want 7 outputs) and 'softmax' activation\n",
    "model2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 407.3210 - accuracy: 0.8011 - val_loss: 2.6936 - val_accuracy: 0.9718\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 4.7547 - accuracy: 0.9688 - val_loss: 4.0098 - val_accuracy: 0.9831\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 1.9893 - accuracy: 0.9844 - val_loss: 71.7428 - val_accuracy: 0.5876\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 505.5879 - accuracy: 0.7784 - val_loss: 932.9272 - val_accuracy: 0.8644\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 370.7786 - accuracy: 0.8125 - val_loss: 116.8977 - val_accuracy: 0.8644\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 92.2633 - accuracy: 0.8281 - val_loss: 250.4793 - val_accuracy: 0.8644\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 90.9709 - accuracy: 0.8679 - val_loss: 24.3265 - val_accuracy: 0.8362\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 130.1619 - accuracy: 0.8338 - val_loss: 56.1669 - val_accuracy: 0.8927\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 41.3121 - accuracy: 0.9062 - val_loss: 97.9021 - val_accuracy: 0.8644\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 41.4068 - accuracy: 0.9148 - val_loss: 58.7068 - val_accuracy: 0.8870\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created the model and loaded your data\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 58.7068 - accuracy: 0.8870\n",
      "Test loss: 58.70676803588867, Test accuracy: 0.887005627155304\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = '/Users/dheemankumar/Desktop/FILE/audio-ai/3sec_audio/hindi_sample_759.wav'  # Adjust the path as needed\n",
    "audio, sample_rate = librosa.load(audio_file_path, sr=22050)  # Load audio with a sample rate of 22050\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d=librosa.stft(audio)\n",
    "s_db=librosa.amplitude_to_db(np.abs(d),ref=np.max)\n",
    "\n",
    "s_db_with_channel = np.expand_dims(s_db, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = tf.convert_to_tensor(audio, dtype=tf.float32)\n",
    "audio_= np.array(s_db_with_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(66150,), dtype=float32, numpy=\n",
       "array([ 0.00295096,  0.00475461,  0.00419691, ..., -0.12367675,\n",
       "       -0.11059908, -0.11454123], dtype=float32)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 130, 1)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = audio_.reshape(1, 1025, 130, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
